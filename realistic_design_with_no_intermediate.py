# -*- coding: utf-8 -*-
"""Realistic design with no intermediate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tybwPOGUgBivp1OpiuNoUCj9b8yaTpcB
"""

!pip install diffusers transformers accelerate gradio

import torch
import gradio as gr
from PIL import Image
from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline

# Check GPU
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load models (optimized to load only once)
text_to_img_pipe = StableDiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-1",
    torch_dtype=torch.float16
).to(device)

img2img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
).to(device)

animegan_model = torch.hub.load(
    "bryandlee/animegan2-pytorch:main",
    "generator",
    pretrained=True,
    device=device
)
face2paint = torch.hub.load(
    "bryandlee/animegan2-pytorch:main",
    "face2paint",
    size=512,
    device=device
)

# Combined function: Text ‚Üí Anime ‚Üí Realistic
def generate_realistic_interior(prompt, strength=0.4):
    # Step 1: Generate anime image from text
    anime_image = text_to_img_pipe(prompt).images[0]
    anime_image = anime_image.convert("RGB")

    # Step 2: Apply AnimeGANv2 (optional, comment if unwanted)
    anime_image = face2paint(animegan_model, anime_image)

    # Step 3: Convert anime to realistic
    realistic_image = img2img_pipe(
        prompt="high-quality realistic interior design, photorealistic, 4k",
        image=anime_image,
        strength=strength
    ).images[0]

    return realistic_image

# Gradio UI (simplified)
with gr.Blocks() as demo:
    gr.Markdown("# üè° Auto-Realistic Interior Generator")

    with gr.Row():
        prompt_input = gr.Textbox(label="Describe your interior", placeholder="e.g., A minimalist Scandinavian living room")
        strength_slider = gr.Slider(0.1, 0.8, value=0.5, label="Realism Strength")
        generate_btn = gr.Button("Generate Realistic Design")

    output_image = gr.Image(label="Realistic Interior Output")

    generate_btn.click(
        fn=generate_realistic_interior,
        inputs=[prompt_input, strength_slider],
        outputs=output_image
    )

demo.launch()

!pip install gradio_client

import torch
import gradio as gr
from PIL import Image
from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline
from gradio_client import Client

# Check GPU
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load models (optimized to load only once)
text_to_img_pipe = StableDiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-1",
    torch_dtype=torch.float16
).to(device)

img2img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
).to(device)

animegan_model = torch.hub.load(
    "bryandlee/animegan2-pytorch:main",
    "generator",
    pretrained=True,
    device=device
)
face2paint = torch.hub.load(
    "bryandlee/animegan2-pytorch:main",
    "face2paint",
    size=512,
    device=device
)

# Combined function: Text ‚Üí Anime ‚Üí Realistic
def generate_realistic_interior(prompt, strength=0.4):
    # Step 1: Generate anime image from text
    anime_image = text_to_img_pipe(prompt).images[0]
    anime_image = anime_image.convert("RGB")

    # Step 2: Apply AnimeGANv2 (optional, comment if unwanted)
    anime_image = face2paint(animegan_model, anime_image)

    # Step 3: Convert anime to realistic
    realistic_image = img2img_pipe(
        prompt="high-quality realistic interior design, photorealistic, 4k",
        image=anime_image,
        strength=strength
    ).images[0]

    return realistic_image

# Run Gradio as an API
demo = gr.Interface(
    fn=generate_realistic_interior,
    inputs=["text", gr.Slider(0.1, 0.8, value=0.5, label="Realism Strength")],
    outputs="image"
)

demo.launch(share=True)

# Client Request to the API
client = Client("https://ed77307a8873244992.gradio.live/")
result = client.predict(
    prompt="A cozy modern bedroom with warm lighting",
    strength=0.5,
    api_name="/generate_realistic_interior"
)

# Print result (This should be the generated image)
print(result)

!pip install flask flask_cors pyngrok openai

from flask import Flask, request, jsonify
from flask_cors import CORS
from transformers import pipeline

app = Flask(__name__)
CORS(app)  # Enable CORS for frontend integration

chatbot = pipeline("text-generation", model="microsoft/DialoGPT-medium")

@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    user_input = data.get("message", "")
    response = chatbot(user_input, max_length=100, do_sample=True)
    return jsonify({"response": response[0]['generated_text']})

if __name__ == '__main__':
    app.run()

from pyngrok import ngrok

# Start ngrok tunnel to expose the Flask API
public_url = ngrok.connect(5000)
print(f"Public chatbot URL: {public_url}")